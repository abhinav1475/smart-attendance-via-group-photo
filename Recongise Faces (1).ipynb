{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1lSiXOI74W5GMqwWZmjtxCBqZeh9v0x6X","authorship_tag":"ABX9TyObV9Zxns/noLlSnZOv21ht"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install mtcnn -q"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QD5d64xLN2qg","executionInfo":{"status":"ok","timestamp":1748064330880,"user_tz":-330,"elapsed":11378,"user":{"displayName":"Abhinav Garlapati","userId":"13171559333716980959"}},"outputId":"68b76581-9167-4909-fd15-3334dc0727a0"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"source":["!pip install onnxruntime -q"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j59TzlQ2Psuk","executionInfo":{"status":"ok","timestamp":1748064342955,"user_tz":-330,"elapsed":12050,"user":{"displayName":"Abhinav Garlapati","userId":"13171559333716980959"}},"outputId":"0fe3f10d-1725-40fc-df11-d61f85057d92"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9KIaA2f7O_uL","executionInfo":{"status":"ok","timestamp":1748064389728,"user_tz":-330,"elapsed":46772,"user":{"displayName":"Abhinav Garlapati","userId":"13171559333716980959"}},"outputId":"171acd62-5474-48b1-8282-a01fd3f27cb5"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/439.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m174.1/439.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for insightface (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["pip install insightface opencv-python scikit-learn matplotlib joblib -q"]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import joblib\n","import matplotlib.pyplot as plt\n","from insightface.app import FaceAnalysis\n","from sklearn.metrics.pairwise import cosine_similarity\n"],"metadata":{"id":"DQFx6OB7PTso","executionInfo":{"status":"ok","timestamp":1748064411964,"user_tz":-330,"elapsed":17717,"user":{"displayName":"Abhinav Garlapati","userId":"13171559333716980959"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"daa26281-7992-4ced-feab-773bb06be2c4"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.7' (you have '2.0.6'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n","  check_for_updates()\n"]}]},{"cell_type":"code","source":["def load_model(ctx_id=0):\n","    face_app = FaceAnalysis(name='buffalo_l')  # ArcFace + MTCNN\n","    face_app.prepare(ctx_id=ctx_id)  # 0 for CPU, 1 for GPU\n","    return face_app\n"],"metadata":{"id":"rRYgO353PbAU","executionInfo":{"status":"ok","timestamp":1748064411983,"user_tz":-330,"elapsed":3,"user":{"displayName":"Abhinav Garlapati","userId":"13171559333716980959"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def load_embeddings(embedding_path, label_path):\n","    embeddings = joblib.load(embedding_path)\n","    labels = joblib.load(label_path)\n","    return embeddings, labels\n"],"metadata":{"id":"5iOo0JKgPbhU","executionInfo":{"status":"ok","timestamp":1748064412013,"user_tz":-330,"elapsed":4,"user":{"displayName":"Abhinav Garlapati","userId":"13171559333716980959"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def recognize_faces(image_path, embeddings, labels, face_app, threshold=0.5):\n","    img = cv2.imread(image_path)\n","    faces = face_app.get(img)\n","\n","    if not faces:\n","        print(\"No faces detected.\")\n","        return [], []\n","\n","    detected_labels = []\n","    unknown_faces = 0\n","    face_results = []\n","\n","    for face in faces:\n","        emb = face.embedding\n","        bbox = np.array(face.bbox, dtype=int)\n","\n","        sims = cosine_similarity([emb], embeddings)\n","        best_match_idx = np.argmax(sims)\n","        best_score = sims[0][best_match_idx]\n","        predicted_label = labels[best_match_idx]\n","\n","        if best_score >= threshold:\n","            label_text = f\"{predicted_label} ({best_score:.2f})\"\n","            detected_labels.append(predicted_label)\n","        else:\n","            label_text = f\"Unknown ({best_score:.2f})\"\n","            predicted_label = \"Unknown\"\n","            unknown_faces += 1\n","\n","\n","        # Annotate bounding box and label\n","        x1, y1, x2, y2 = bbox\n","        color = (0, 255, 255) if predicted_label != \"Unknown\" else (0, 0, 255)  # Yellow for known, Red for unknown\n","        cv2.rectangle(img, (x1, y1), (x2, y2), color, thickness=3)\n","\n","        # Draw label background\n","        label_size, _ = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)\n","        label_width, label_height = label_size\n","        cv2.rectangle(img, (x1, y1 - label_height - 10), (x1 + label_width + 5, y1), color, cv2.FILLED)\n","\n","        # Put label text\n","        cv2.putText(img, label_text, (x1 + 2, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)\n","        # Print label with score\n","        print(f\"Detected: {label_text}\")\n","        face_results.append((predicted_label, best_score, bbox.tolist()))\n","\n","    # Show final image\n","    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    plt.figure(figsize=(12, 10))\n","    plt.imshow(img_rgb)\n","    plt.axis('off')\n","    plt.title(\"Recognized Faces\")\n","    plt.show()\n","\n","    # Determine present vs absent\n","    all_known_labels = set(labels)\n","    detected_labels_set = set(detected_labels)\n","    absent_labels = sorted(all_known_labels - detected_labels_set)\n","    present_labels = sorted(detected_labels_set)\n","\n","    print(\"\\n--- Attendance Report ---\")\n","    print(f\"‚úÖ Present ({len(present_labels)}): {present_labels}\")\n","    print(f\"‚ùå Absent ({len(absent_labels)}): {absent_labels}\")\n","    if unknown_faces > 0:\n","        print(f\"‚ùì Unknown Faces: {unknown_faces}\")\n","\n","    return face_results, present_labels\n","\n","\n","#group img 1 : ground truth : 5451 5453: path : /content/drive/MyDrive/Mini/group images/group img 1.jpg\n","#group img 4 : ground truth: 5440 5461 path: /content/drive/MyDrive/Mini/group images/group img 4.jpg\n","#group_test_1 : ground truth: 5413 5452 5451 5409 5423 5449 5445 path : /content/drive/MyDrive/Mini/group images/group_test_1.jpg\n","#group_test_2: ground truth: 5413 5452 5451 5409 5435 5423 5449 5445 path: /content/drive/MyDrive/Mini/group images/group_test_2.jpg\n"],"metadata":{"id":"dKu-vG8PPeOK","executionInfo":{"status":"ok","timestamp":1748064499265,"user_tz":-330,"elapsed":23,"user":{"displayName":"Abhinav Garlapati","userId":"13171559333716980959"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["import pickle\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","\n","# Ground truth for test images\n","TEST_IMAGES = [\n","    (\"/content/drive/MyDrive/Mini/group images/group img 1.jpg\", [\"5451\", \"5453\"]),\n","    (\"/content/drive/MyDrive/Mini/group images/group img 4.jpg\", [\"5440\", \"5461\"]),\n","    (\"/content/drive/MyDrive/Mini/group images/group_test_1.jpg\", [\"5413\", \"5452\", \"5451\", \"5409\", \"5423\", \"5449\", \"5445\"]),\n","    (\"/content/drive/MyDrive/Mini/group images/group_test_2.jpg\", [\"5413\", \"5452\", \"5451\", \"5409\", \"5435\", \"5423\", \"5449\", \"5445\"]),\n","]\n","\n","def evaluate_model_on_tests(embeddings, labels, face_app, threshold=0.7):\n","    results = []\n","\n","    for img_path, ground_truth in TEST_IMAGES:\n","        print(f\"\\nüß™ Testing: {img_path.split('/')[-1]}\")\n","        face_results, detected = recognize_faces(\n","            image_path=img_path,\n","            embeddings=embeddings,\n","            labels=labels,\n","            face_app=face_app,\n","            threshold=threshold\n","        )\n","\n","        # Metrics\n","        correct = set(detected) & set(ground_truth)\n","        acc = len(correct) / len(ground_truth)\n","\n","        y_true = [1 if label in ground_truth else 0 for label in labels]\n","        y_pred = [1 if label in detected else 0 for label in labels]\n","\n","        precision = precision_score(y_true, y_pred, zero_division=0)\n","        recall = recall_score(y_true, y_pred, zero_division=0)\n","        f1 = f1_score(y_true, y_pred, zero_division=0)\n","\n","        print(f\"‚úÖ Accuracy: {acc:.2f}, üéØ Precision: {precision:.2f}, üîÅ Recall: {recall:.2f}, üßÆ F1: {f1:.2f}\")\n","\n","        results.append({\n","            \"image\": img_path.split('/')[-1],\n","            \"accuracy\": acc,\n","            \"precision\": precision,\n","            \"recall\": recall,\n","            \"f1\": f1\n","        })\n","\n","    return results\n","\n","\n","def plot_metrics(results):\n","    metrics = [\"accuracy\", \"precision\", \"recall\", \"f1\"]\n","    x_labels = [r[\"image\"] for r in results]\n","    x = np.arange(len(x_labels))\n","    width = 0.2\n","\n","    # Set up the figure with high DPI (300) for publication quality\n","    plt.figure(figsize=(12, 6), dpi=300)\n","\n","    # Update font sizes for clarity\n","    plt.rc('font', size=12)\n","    plt.rc('axes', titlesize=16, labelsize=14)\n","    plt.rc('xtick', labelsize=12)\n","    plt.rc('ytick', labelsize=12)\n","    plt.rc('legend', fontsize=12)\n","\n","    # Plot each metric\n","    for i, metric in enumerate(metrics):\n","        plt.bar(x + i * width, [r[metric] for r in results], width, label=metric.capitalize())\n","\n","    plt.xticks(x + 1.5 * width, x_labels, rotation=15)\n","    plt.xlabel(\"Group Image\", fontsize=14)\n","    plt.ylabel(\"Score\", fontsize=14)\n","    plt.title(\"Face Recognition Performance per Group Image\", fontsize=16)\n","    plt.ylim(0, 1.05)\n","    plt.legend(loc=\"best\")\n","    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n","    plt.tight_layout()\n","\n","    # Save the high DPI figure for publication quality output\n","    save_path = '/content/drive/MyDrive/Mini/performance_metrics_paper_ready.png'\n","    plt.savefig(save_path, bbox_inches='tight', dpi=300)\n","    print(f\"üìä High DPI performance metrics graph saved to {save_path}\")\n","\n","    plt.show()\n"],"metadata":{"id":"6r640pTZJZWt","executionInfo":{"status":"ok","timestamp":1748064412031,"user_tz":-330,"elapsed":15,"user":{"displayName":"Abhinav Garlapati","userId":"13171559333716980959"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def main():\n","    #File paths\n","    EMB_PATH = '/content/drive/MyDrive/Mini/embeddings.pkl'\n","    LABEL_PATH = '/content/drive/MyDrive/Mini/labels.pkl'\n","    IMG_PATH = '/content/drive/MyDrive/Mini/group images/group_test_2.jpg'\n","\n","    #Load models and data\n","    face_app = load_model(ctx_id=0)\n","    embeddings, labels = load_embeddings(EMB_PATH, LABEL_PATH)\n","\n","    # Run recognition\n","    recognize_faces(IMG_PATH, embeddings, labels, face_app, threshold=0.7)"],"metadata":{"id":"a_m3uir2QSIF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def main():\n","    EMB_PATH = '/content/drive/MyDrive/Mini/embeddings.pkl'\n","    LABEL_PATH = '/content/drive/MyDrive/Mini/labels.pkl'\n","\n","    print(\"üì¶ Loading ArcFace model...\")\n","    face_app = load_model(ctx_id=0)\n","\n","    print(\"üìÇ Loading embeddings and labels...\")\n","    embeddings, labels = load_embeddings(EMB_PATH, LABEL_PATH)\n","\n","    print(\"üöÄ Starting Evaluation...\")\n","    results = evaluate_model_on_tests(embeddings, labels, face_app, threshold=0.7)\n","\n","    print(\"üìä Generating Graphs...\")\n","    plot_metrics(results)"],"metadata":{"id":"kcRSiyXHPaa_","executionInfo":{"status":"ok","timestamp":1748064463660,"user_tz":-330,"elapsed":44,"user":{"displayName":"Abhinav Garlapati","userId":"13171559333716980959"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","  main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1IRdPP8REiROR1U2Nr6x8jj4nRr25JVY-"},"id":"MPiqcX_gVOJK","executionInfo":{"status":"ok","timestamp":1748064549895,"user_tz":-330,"elapsed":45632,"user":{"displayName":"Abhinav Garlapati","userId":"13171559333716980959"}},"outputId":"df4b8c52-57c1-49e7-9c88-b62ebc00e919"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["import pickle\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.metrics import roc_curve, auc\n","import shutil\n","import os"],"metadata":{"id":"F2127QhtRHwe","executionInfo":{"status":"ok","timestamp":1748064638053,"user_tz":-330,"elapsed":53,"user":{"displayName":"Abhinav Garlapati","userId":"13171559333716980959"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import pickle\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, auc\n","from sklearn.metrics.pairwise import cosine_similarity\n","import shutil\n","import os\n","\n","# Existing functions (unchanged):\n","# - load_model\n","# - load_embeddings\n","# - plot_metrics (not called)\n","# - collect_roc_data\n","# - TEST_IMAGES\n","# - evaluate_model_on_tests\n","# - recognize_faces\n","\n","# Updated plot_roc_curve with enhancements for publication\n","def plot_roc_curve(true_labels, sim_scores):\n","    try:\n","        fpr, tpr, thresholds = roc_curve(true_labels, sim_scores, pos_label=1)\n","        roc_auc = auc(fpr, tpr)\n","        eer = fpr[np.argmin(np.abs(fpr - (1 - tpr)))] if len(fpr) > 0 else 0\n","        eer_tpr = 1 - eer  # TPR at EER\n","\n","        plt.figure(figsize=(8, 6))\n","        plt.plot(fpr, tpr, color='blue', lw=3, label=f'ROC Curve (AUC = {roc_auc:.3f})')  # Thicker line, AUC to 3 decimals\n","        plt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=1)\n","        plt.scatter([eer], [eer_tpr], color='red', marker='o', s=100, label=f'EER = {eer:.3f}')\n","        # Add label next to EER marker\n","        plt.text(eer + 0.02, eer_tpr - 0.05, f'EER = {eer:.3f}', fontsize=10, color='red')\n","\n","        plt.xlim([0.0, 0.2])  # Zoom in on low FPRs\n","        plt.ylim([0.0, 1.05])\n","        plt.xlabel('False Positive Rate (FPR)', fontsize=12)\n","        plt.ylabel('True Positive Rate (TPR)', fontsize=12)\n","        plt.title('ROC Curve for Face Recognition on Test Group Images', fontsize=14, pad=15)\n","        plt.legend(loc='lower right', fontsize=11)\n","        plt.grid(True, linestyle='--', alpha=0.5)  # Lighter grid\n","        plt.tight_layout()\n","\n","        # Save the plot\n","        save_path = '/content/drive/MyDrive/Mini/roc_curve7.png'\n","        plt.savefig(save_path, bbox_inches='tight', dpi=300)  # Higher DPI for publication\n","        print(f\"üìà ROC curve saved to {save_path}\")\n","\n","        # Display the plot in Colab\n","        plt.show()\n","        plt.close()\n","\n","        # Verify file exists\n","        if os.path.exists(save_path):\n","            print(f\"‚úÖ Verified: ROC curve file exists at {save_path}\")\n","        else:\n","            print(f\"‚ùå Error: ROC curve file not found at {save_path}\")\n","\n","        return roc_auc, eer\n","    except Exception as e:\n","        print(f\"Error generating ROC curve plot: {e}\")\n","        return None, None\n"],"metadata":{"id":"JHBabp4pRHuX","executionInfo":{"status":"ok","timestamp":1748064638939,"user_tz":-330,"elapsed":6,"user":{"displayName":"Abhinav Garlapati","userId":"13171559333716980959"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_9rRmPicRHsM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wO7PlLxMWfqA"},"execution_count":null,"outputs":[]}]}